{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 손실함수 구하는 것\r\n",
    "# 오차 제곱합 \r\n",
    "# y : 출력 (신경망이 추정한 값)\r\n",
    "# t : 정답 레이블\r\n",
    "def sum_squares_error(y, t):\r\n",
    "    return 0.5 * np.sum((y-t)**2) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\r\n",
    "y1 = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\r\n",
    "y2 = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\r\n",
    "\r\n",
    "loss1 = sum_squares_error(np.array(y1), np.array(t))\r\n",
    "loss2 = sum_squares_error(np.array(y2), np.array(t))\r\n",
    "\r\n",
    "loss1, loss2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.09750000000000003, 0.5975)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 교차 엔트로피 오차 : Cross entropy error : CEE\r\n",
    "# delta 더한 이유 : y가 0일 때 마이너스 무한대인 -inf가 되어 계산을 진행 할 수 없기때문에 최소 값을 만들어 놓음\r\n",
    "def CEE(y, t):\r\n",
    "    delta = 1e-7\r\n",
    "    return -np.sum(t * np.log(y + delta))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\r\n",
    "y1 = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\r\n",
    "y2 = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\r\n",
    "\r\n",
    "loss1 = CEE(np.array(y1), np.array(t))\r\n",
    "loss2 = CEE(np.array(y2), np.array(t))\r\n",
    "\r\n",
    "loss1, loss2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.510825457099338, 2.302584092994546)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import sys, os\r\n",
    "sys.path.append(os.pardir)\r\n",
    "import numpy as np \r\n",
    "from dataset.mnist import load_mnist\r\n",
    "\r\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, one_hot_label = True)\r\n",
    "\r\n",
    "print(x_train.shape)\r\n",
    "print(t_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# 훈련데이터에서 10장만 무작위로 뽑음 \r\n",
    "\r\n",
    "train_size = x_train.shape[0]\r\n",
    "batch_size = 10\r\n",
    "\r\n",
    "# np.random.choice는 지정한 범위의 수 중에서 무작위로 원하는 개수만 꺼낼수 있다. \r\n",
    "# 즉, train_size : 60000개에서 batch_size : 10개를 무작위로 골라내는 것\r\n",
    "batch_mask = np.random.choice(train_size, batch_size)\r\n",
    "x_batch = x_train[batch_mask] \r\n",
    "t_batch = t_train[batch_mask]\r\n",
    "\r\n",
    "# 데이터의 인덱스로 사용하는 것 \r\n",
    "batch_mask"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([58460, 34987, 59065, 40807, 39609, 39199,  9570, 23356, 54440,\n",
       "        1693])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# batch_size 용 교차 엔트로피 오차 \r\n",
    "def CEE(y, t):\r\n",
    "    if y.ndim == 1:\r\n",
    "        t = t.reshape(1, t.size)\r\n",
    "        y = y.reshape(1, y.size)\r\n",
    "\r\n",
    "    batch_size = y.shape[0]\r\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "## 미분 나쁜 구현 \r\n",
    "## 이유 : h에 너무 작은 값 (0.00000~~~1) 형태는 반올림 오차를 일으킴 \r\n",
    "## 반올림 오차 : 작은 값은 생략되는 것 -> 결과에 오차가 생김 \r\n",
    "def numerical_diff(f, x):\r\n",
    "    h = 10e-50\r\n",
    "    return (f(x+h) - f(x)) / h"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "np.float32(1e-50)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "## 개선된 수치 미분\r\n",
    "def numerical_diff(f, x):\r\n",
    "    h = 1e-4 # 0.0001 \r\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def function_1(x):\r\n",
    "    return 0.01*x**2 + 0.1*x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pylab as plt\r\n",
    "\r\n",
    "x = np.arange(0.0, 20.0, 0.1) \r\n",
    "y = function_1(x)\r\n",
    "\r\n",
    "plt.xlabel(\"x\")\r\n",
    "plt.ylabel(\"y\")\r\n",
    "plt.plot(x,y)\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiF0lEQVR4nO3deXhV1b3/8feXhDCEMQMzAcIkgyAYSFBKnYtcKmrVgkWKMmirVnqv9Xprf9ZW77WD9Wq1taKgIKPzgCPOUiEQIIwBEoYQpgyMgUBCkvX7I4dexAQDZGefc/J5PU+enJy9T9aXffb5sLP22mubcw4REQk/9fwuQEREvKGAFxEJUwp4EZEwpYAXEQlTCngRkTAV6XcBJ4uLi3OdO3f2uwwRkZCxfPnyAudcfGXLgirgO3fuTFpamt9liIiEDDPLrmqZumhERMKUAl5EJEwp4EVEwpSnAW9mLczsVTPbYGYZZjbEy/ZEROT/eH2S9UngA+fcDWYWBTT2uD0REQnwLODNrDkwDBgP4JwrAUq8ak9ERL7Jyy6aLkA+8IKZrTSz580s2sP2RETkJF4GfCQwEHjGOTcAOALcf+pKZjbZzNLMLC0/P9/DckREgs/y7H089+UWT363lwG/A9jhnEsN/PwqFYH/Dc65qc65JOdcUnx8pRdjiYiEpYzdh7j1hWXMTs3mSHFpjf9+zwLeObcHyDGznoGnLgfWe9WeiEgo2VZwhFumLaVxVCQvTUgmukHNnxL1ehTN3cDswAiaLcCtHrcnIhL09hw8xthpqZSVlzNv8hA6xngzwNDTgHfOpQNJXrYhIhJKDhSVMG56KvuPlDB3cgrdWjX1rK2gmmxMRCScHSkuZfwLy9i2t4gXbx1Evw4tPG1PUxWIiNSCY8fLmDgjjTU7D/L0mAFc1DXO8zYV8CIiHispLefns1ewZOte/nJjf67q06ZW2lXAi4h4qKzc8cv56Xy6IY//vvZ8rh3QvtbaVsCLiHikvNzxn6+t5t01u3lgRC9uTk6o1fYV8CIiHnDO8bt31vHq8h3cc3l3Jg1LrPUaFPAiIh7484cbmbE4m4lDuzDliu6+1KCAFxGpYX/7LIu/f76ZMYMTeODfemFmvtShgBcRqUEv/nMrf/5wI6MuaMcj1/b1LdxBAS8iUmNeTsvhoXfWc2Xv1jx2Y38i6vkX7qCAFxGpEQtW7+L+11bzve5xPH3zAOpH+B+v/lcgIhLiPt2Qy5R56VzYqSXP3nIhDSIj/C4JUMCLiJyTrzLzuWPWCnq1bca08YNoHBU8U3wp4EVEztLXmwuYOCONxLhoZt42mGYN6/td0jco4EVEzsLSrfuY8GIaCTGNmT0xmZbRUX6X9C0KeBGRM7Q8ez+3vrCUti0aMntSMrFNGvhdUqUU8CIiZ2BVzgHGT19KfNMGzJ2UQqumDf0uqUoKeBGRalq78yC3TEulRXR95kxKoXWz4A13UMCLiFRLxu5DjJ2WStOG9ZkzMYV2LRr5XdJ3UsCLiHyHzNxCxj6fSsPICOZMSvbsJtk1TQEvInIam/MPM+a5VOrVM+ZMSqZTbLTfJVWbAl5EpArbCo5w83NLAMfcSckkxjfxu6QzooAXEalEzr4ibn5uCSWl5cyemEK3Vk39LumMBc81tSIiQSJnXxGjpy7hSEkZcyYl07NN6IU7KOBFRL5h+94iRk9dzJGSMmZPTKZPu+Z+l3TWPA14M9sGFAJlQKlzLsnL9kREzkX23iOMmbqEouMV4d63feiGO9TOEfylzrmCWmhHROSsbSs4wpjnlnDseBlzJqbQu10zv0s6Z+qiEZE6b2tBxZF7SVk5cyal0Ktt6Ic7eD+KxgEfmdlyM5tc2QpmNtnM0swsLT8/3+NyRES+aUv+YUZPXRwI9+SwCXfwPuCHOucGAlcDd5rZsFNXcM5Ndc4lOeeS4uPjPS5HROT/bM4/zOipSygtc8ydlMJ5bcIn3MHjgHfO7Qx8zwPeAAZ72Z6ISHVl5VWEe7lzzJ2cErJDIU/Hs4A3s2gza3riMXAVsNar9kREqisrr5DRU5fgHMydlEKP1uEX7uDtSdbWwBtmdqKdOc65DzxsT0TkO2XmFjLmuSWYGXMnpdCtVWhNP3AmPAt459wWoL9Xv19E5Ext3FPIT56vG+EOmotGROqItTsP8uOpi4moZ8ybHP7hDgp4EakDlmfvZ8xzS4iOiuTl24fQNcRmhTxbutBJRMLa4s17mTBjGa2aNmD2pBTah8CdmGqKAl5EwtYXm/KZPDONhJjGzJ6YTKsgv4dqTVPAi0hYWrg+lztnr6BrqybMmjCY2CYN/C6p1ingRSTsLFi9iynz0unTvjkzbx1M88b1/S7JFzrJKiJh5bXlO/jF3JUMSGjBrAl1N9xBR/AiEkZmp2bzwBtrubhbLM+NS6JxVN2OuLr9rxeRsDFt0VYeXrCey85rxd9/MpCG9SP8Lsl3CngRCXl/+yyLP3+4kav7tuHJ0QOIilTvMyjgRSSEOef4wwcbePaLLVx7QTseu7E/kREK9xMU8CISksrKHb95cw1zl+YwNiWB31/Tl3r1zO+ygooCXkRCTklpOb98OZ13V+/mzku7cu9VPQnMXCsnUcCLSEg5WlLGHbOW88WmfH494jwmD+vqd0lBSwEvIiHj4NHjTHhxGSu27+ePPzqfHw9K8LukoKaAF5GQkF9YzLjpS8nKK+Tpmwcy4vy2fpcU9BTwIhL0duwvYuzzqeQeKmbaTwcxrEe83yWFBAW8iAS1rLxCxj6/lKKSUmZNTObCTi39LilkKOBFJGit3nGAn05fSkS9esy/fQi92jbzu6SQooAXkaC0ZMteJs5Io0Xj+syakEznuGi/Swo5CngRCTrvr9nNPfPT6RTTmJcmJNOmed26UUdNUcCLSFB5aUk2D761lgEdWzB9/CBaNI7yu6SQpYAXkaDgnOPxhZt46tMsrujViqfGDKRRlGaEPBcKeBHxXWlZOb95cy3zluXw46SO/Pd1fTVpWA3wPODNLAJIA3Y650Z63Z6IhJajJWXcPXclH2fkcvdl3fj3K3toXpkaUhtH8PcAGYDGN4nINxwoKmHCjDRWbN/Pw6P6cMuQzn6XFFY8/RvIzDoA/wY872U7IhJ6dh04yg3/WMyaHQf5+80DFe4e8PoI/gngPqBpVSuY2WRgMkBCgiYOEqkLNuUWMm7aUo4UlzJzwmBSEmP9LikseXYEb2YjgTzn3PLTreecm+qcS3LOJcXHa34JkXC3bNs+bnjma8qd4+U7hijcPeTlEfzFwDVmNgJoCDQzs1nOubEetikiQeyDtXu4Z95K2rdsxMzbBtOhZWO/Swprnh3BO+f+yznXwTnXGRgNfKpwF6m7pi3ays9mL6d3u2a8esdFCvdaoHHwIuKpsnLHwwvW8+LX2xjepw1PjL6AhvV1AVNtqJWAd859DnxeG22JSPA4WlLGL+atZOH6XCYM7cKvR/QiQjfGrjU6ghcRT+QXFjNxxjJW7zzIQz/szfiLu/hdUp2jgBeRGrc5/zDjX1hKfmExz469kKv6tPG7pDpJAS8iNWrp1n1MmplG/Qhj3uQhXNCxhd8l1VkKeBGpMW+v2sW9L6+iQ0wjXhw/mIRYjZTxkwJeRM6Zc45nvtjMnz7YyOAuMUy95ULN4x4EFPAick6Ol5Xz4FvrmLt0O9f0b8efb+xHg0gNgwwGCngROWsHi45z55wVLMoq4GeXdOVXV/WknoZBBg0FvIiclW0FR7htxjJy9hXxpxv6cVNSR79LklMo4EXkjC3evJefza6YR3DWhGSSNWFYUFLAi8gZmb9sOw+8sZZOsY2ZPn4QnWKj/S5JqqCAF5FqKSt3/PGDDUz9cgvf6x7H0zcPpHmj+n6XJaehgBeR73S4uJQp81bycUYe44Z04sGRvXVT7BCggBeR09p54CgTXlxGZt5hfj+qD+N0a72QoYAXkSqt2L6fyTOXU3y8jBfGD2JYD911LZQo4EWkUm+l7+RXr66mTbOGzJ2UTPfWVd5aWYKUAl5EvqGs3PHnDzfyjy82M7hzDP+45UJiojXtQChSwIvIvxw8epx75q3k84353JycwEM/7ENUpE6mhioFvIgAkJV3mEkz08jZV8Qj1/ZlbEonv0uSc6SAFxE+ychlyrx0oiLrMWdSCoO7xPhdktQABbxIHeac4++fb+axjzbSp10znr0lifYtGvldltQQBbxIHVVUUsqvXlnNu2t2M+qCdvzh+n40itI0v+FEAS9SB+XsK2LSzDQ25Rby6xHnMel7iZhpmt9wo4AXqWO+3lzAnbNXUFbueOHWwXxfFy+FLQW8SB3hnOOFf27jv9/LoEtcNM+NS6JLnGaCDGeeBbyZNQS+BBoE2nnVOfdbr9oTkaodKS7l/tfX8M6qXVzZuzWP39Sfpg01E2S48/IIvhi4zDl32MzqA4vM7H3n3BIP2xSRU2zOP8wdLy1nc/5h7hvekzuGddVt9eoIzwLeOeeAw4Ef6we+nFftici3fbB2D/e+soqoyHq8NCGZi7vF+V2S1KLvvAbZzO42s5Zn88vNLMLM0oE8YKFzLrWSdSabWZqZpeXn559NMyJyitKych59P4M7Zi2na6smLLh7qMK9DqrOJBOtgWVm9rKZDbczGEvlnCtzzl0AdAAGm1nfStaZ6pxLcs4lxcfrbL7IuSo4XMwt05by7BdbGJuSwMu3p9BOFy/VSd8Z8M653wDdgWnAeCDTzP7HzLpWtxHn3AHgM2D42ZUpItWxYvt+Rv51ESu27+exG/vzyLXn0yBSFy/VVdWaJi7Qn74n8FUKtAReNbM/VfUaM4s3sxaBx42AK4EN51qwiHybc46Zi7fx42cXUz/SeP3nF3HDhR38Lkt89p0nWc3sHmAcUAA8D/zKOXfczOoBmcB9Vby0LTDDzCKo+I/kZefcgpopW0ROKCop5TdvrOX1lTu57LxW/O9NF9C8sYZASvVG0cQA1zvnsk9+0jlXbmYjq3qRc241MOAc6xOR08jMLeTns1eQlX+Yf7+yB3dd2k1DIOVfvjPgT3dxknMuo2bLEZHqem35Dn7z5lqiG0Tw0m3JDO2uUTLyTZqqQCTEHC0p48G31vLK8h2kJMbw19EDaNWsod9lSRBSwIuEkKy8ii6ZzLzD/OKybtxzRQ8i1CUjVVDAi4SI11fs4IE31tI4KoKZtw3me9113YicngJeJMgdLSnjobfXMT8th+QuMfx1zABaq0tGqkEBLxLEsvIKuXP2SjblFXL3Zd245/LuREZU6/IVEQW8SDByzjF/WQ4PvbOO6KhIZtw6mGG6MYecIQW8SJA5ePQ4v359De+u2c3QbnE8flN/jZKRs6KAFwkiadv2cc+8dHIPHeP+q89j8vcSdeGSnDUFvEgQKCt3/O2zLJ74eBMdYxrz6s8u4oKOLfwuS0KcAl7EZ7sOHGXK/HSWbt3HdQPa8/tRfXQ7PakRCngRH32wdg//+dpqSsvKefym/lw/UDNASs1RwIv4oKiklEfezWBO6nbOb9+cv44ZQJe4aL/LkjCjgBepZek5B/jl/HS27T3C7cMS+Y+rehIVqbHtUvMU8CK1pLSsnKc/y+KpT7No06whcyelkJIY63dZEsYU8CK1YGvBEabMT2dVzgGuG9Ce343qQzOdSBWPKeBFPOScY+7SHB5esJ6oyHo8ffMARvZr53dZUkco4EU8kl9YzP2vreaTDXkM7RbHYzf2p01zXZEqtUcBL+KBhetzuf+11RQWl/LgyN6Mv6izrkiVWqeAF6lBB4uO87sF63h9xU56tW3G3NEX0KN1U7/LkjpKAS9SQz7bmMf9r62m4HAJv7isG3dd1l3DH8VXCniRc1R47DiPLMhgfloO3Vs14blxSfTr0MLvskQU8CLnYlFmAfe9uoo9h45xx/e7MuWK7jSsH+F3WSKAAl7krBwpLuXR9zOYtWQ7ifHRvPqzixiY0NLvskS+wbOAN7OOwEygNeCAqc65J71qT6S2LNmyl1+9uood+48ycWgX7v1BTx21S1Dy8gi+FPgP59wKM2sKLDezhc659R62KeKZwmPH+cP7G5idup1OsY15+fYhDOoc43dZIlXyLOCdc7uB3YHHhWaWAbQHFPAScj7JyOU3b64l99AxJg7twr9f1YPGUerhlOBWK3uomXUGBgCplSybDEwGSEhIqI1yRKpt7+FifvfOet5etYuerZvyzNgLdaclCRmeB7yZNQFeA6Y45w6dutw5NxWYCpCUlOS8rkekOpxzvJW+i9+9s47DxaX88ooe/OySrhrXLiHF04A3s/pUhPts59zrXrYlUlN2HTjKA2+s4bON+QxIaMEff9RPV6NKSPJyFI0B04AM59zjXrUjUlPKyx2zU7P5w/sbKHfw4Mje/PSizkRoDhkJUV4ewV8M3AKsMbP0wHO/ds6952GbImclY/chfv3GGlZuP8DQbnE8ev35dIxp7HdZIufEy1E0iwAd+khQKyop5YmPM5m2aCstGtXn8Zv6c92A9lT8ASoS2jTOS+qsj9fn8tu317HzwFFGD+rI/VefR4vGUX6XJVJjFPBS5+w+eJSH3l7Hh+ty6dG6Ca/coQuWJDwp4KXOKC0rZ8bibB7/aCNlznHf8J5MHJqooY8SthTwUies3L6f//fWWtbuPMQlPeN5eFRfnUSVsKeAl7C293Axf/xgAy+n7aBV0wb87eaBjDi/jU6iSp2ggJewVFpWzuzU7fzlo40UlZRx+7BE7r68O00aaJeXukN7u4SdZdv28eBb68jYfYih3eJ46Jo+dGvVxO+yRGqdAl7CRt6hYzz6/gbeWLmTds0b8sxPBjK8r7pjpO5SwEvIO15Wzoyvt/HEx5mUlJZz16Xd+PmlXTWdr9R5+gRIyHLO8dnGPB55N4Mt+Ue4pGc8v/1hH7rERftdmkhQUMBLSNqUW8jDC9bzVWYBiXHRPD8uict7tVJ3jMhJFPASUvYdKeF/F25iztLtREdF8P9G9uaWlE66WEmkEgp4CQklpeXMXLyNJz/JpKikjLHJCUy5ogctozV3jEhVFPAS1JxzLFyfy/+8l8G2vUVc0jOeB0b0ortuwCHynRTwErRW5Rzg0fczWLJlH91aNeGFWwdxac9WfpclEjIU8BJ0svce4U8fbuTd1buJjY7i96P6MGZwAvUj1M8uciYU8BI0Cg4X89QnmcxO3U79iHr84rJuTBqWSNOG9f0uTSQkKeDFd0UlpTz/1VamfrmFo8fL+PGgjky5vDutmjX0uzSRkKaAF9+UlpUzPy2HJz7OJL+wmB/0ac19w8+ja7zmjRGpCQp4qXXl5Y531+zmfz/exJb8IyR1ask/xg7kwk66q5JITVLAS605MeTx8YWb2LCnkB6tmzD1lgu5sndrXYEq4gEFvHjOOcdXmQX85aONrNpxkC5x0Tw5+gJG9mtHRD0Fu4hXFPDiqdQte/nLR5tYum0f7Vs04k839OP6Ae2J1JBHEc8p4MUT6TkH+MtHG/kqs4BWTRvw8Kg+3DSoIw0iI/wuTaTOUMBLjVqevZ+nPs3k8435xERH8cCIXoxN6USjKAW7SG3zLODNbDowEshzzvX1qh0JDqlb9vLUp1ksyiogJjqK+4b3ZNyQzroHqoiPvPz0vQg8Dcz0sA3xkXOOxZv38uQnmaRu3UdckwY8MKIXP0lJ0N2URIKAZ59C59yXZtbZq98v/jkxKuavn2SSlr2f1s0a8Nsf9mbM4AQa1ldXjEiw8P0wy8wmA5MBEhISfK5GTqe83LEwI5dnPt9Mes4B2jVvyMOj+nBjUkcFu0gQ8j3gnXNTgakASUlJzudypBLFpWW8uXInz365hS35R+gY04hHrz+fHw3soDspiQQx3wNeglfhsePMSd3O9H9uJfdQMX3aNeOpMQO4um8bjWMXCQEKePmWvMJjvPDPbcxakk3hsVIu7hbLYzf2Z2i3OE0pIBJCvBwmORe4BIgzsx3Ab51z07xqT87d5vzDPP/VVl5bsYPjZeWM6NuW27+fSL8OLfwuTUTOgpejaMZ49bul5jjnWJRVwPRFW/lsYz5RkfX40cAOTB6WSJe4aL/LE5FzoC6aOurY8YoTp9P/uZVNuYeJa9KAX17Rg5uTE4hv2sDv8kSkBijg65i8Q8d4aUk2s1O3s+9ICb3bNuOxG/vzw/5tNU+MSJhRwNcRq3IO8OLX21iwehel5Y4re7XmtqFdSO4SoxOnImFKAR/GjpaU8c6qXcxKzWb1joNER0UwNqUT4y/qTKdY9a+LhDsFfBjakn+Y2anbeSUth0PHSunRugkPj+rDtQPa07Rhfb/LE5FaooAPE6Vl5XyckcusJdtZlFVA/QhjeN+2jE1OYLC6YUTqJAV8iNuxv4hX0nYwf1kOew4do13zhtx7VQ9uGtSRVk0b+l2eiPhIAR+CikvL+GhdLi+n5bAoqwCAod3i+P2oPlx2XitNIyAigAI+pGTsPsT8ZTm8mb6TA0XHad+iEb+4rDs3JnWgQ8vGfpcnIkFGAR/kDh07ztvpu3g5LYfVOw4SFVGPK/u05sdJHbm4WxwR9dS3LiKVU8AHoZLScr7clM8b6Tv5eH0uxaXlnNemKQ+O7M11A9rTMjrK7xJFJAQo4IOEc46VOQd4c+VO3lm1i/1Fx4mJjmL0oI5cP7AD/To010gYETkjCnifbS04wpsrd/Jm+k6y9xbRILIeV/ZuzXUD2jOsRzz1dcJURM6SAt4Huw4c5b01u1mwejfpOQcwgyGJsdx1aTeG922ji5FEpEYo4GvJ7oNHeW/NHt5dvYsV2w8A0LttM/7r6vO45oJ2tG3eyN8CRSTsKOA9tOfgMd5bs5t31+xmefZ+oCLUf/WDnow4v63mWxcRTynga9i2giMsXJ/Lh+v2kBYI9V5tm3HvVT0YcX5bEuOb+FyhiNQVCvhzVF7uSN9xgIXrc/l4fS6ZeYeBilD/jyt7MKJfW7oq1EXEBwr4s3DseBlfby6oCPWMPPILi4moZyR3ieHm5ASu6NWajjG6slRE/KWAr6acfUV8sSmfzzfm8/XmAopKyoiOiuCSnq24sndrLu3ZiuaNNfpFRIKHAr4Kx46Xkbp1H19szOfzTXlsyT8CQIeWjbh+YHuu6NWaIV1jdZs7EQlaCvgA5xyb8w/zVWYBn2/MZ8mWvRSXlhMVWY+UxFjGJnfi+z3jSYyL1hWlIhIS6mzAO+fYvq+IxZv38vXmvSzespf8wmIAEuOiGTM4gUt6xpPcJZZGUTpKF5HQU6cCfvfBo3ydVRHmizfvZeeBowDEN23AkMRYLuoay0Vd40iI1QlSEQl9nga8mQ0HngQigOedc3/wsr2TlZc7MvMOk5a9j+Xb9pOWvZ/t+4oAaNm4PimJsdzx/USGdI2la3wTdbuISNjxLODNLAL4G3AlsANYZmZvO+fWe9He0ZIy0nMOsDx7H2nZ+1mRvZ9Dx0oBiGsSxYWdWjJuSCcu6hrHeW2aUk/zqItImPPyCH4wkOWc2wJgZvOAUUCNBnxxaRk3PbuEdTsPUlruAOjeqgn/1q8tF3aKIalTSzrFNtYRuojUOV4GfHsg56SfdwDJp65kZpOByQAJCQln3EiDyAi6xDbm4q6xJHVuycCElrRorBtiiIj4fpLVOTcVmAqQlJTkzuZ3PDF6QI3WJCISDry8m8ROoONJP3cIPCciIrXAy4BfBnQ3sy5mFgWMBt72sD0RETmJZ100zrlSM7sL+JCKYZLTnXPrvGpPRES+ydM+eOfce8B7XrYhIiKV0x2dRUTClAJeRCRMKeBFRMKUAl5EJEyZc2d1bZEnzCwfyD7Ll8cBBTVYTk1RXWcuWGtTXWdGdZ25s6mtk3MuvrIFQRXw58LM0pxzSX7XcSrVdeaCtTbVdWZU15mr6drURSMiEqYU8CIiYSqcAn6q3wVUQXWduWCtTXWdGdV15mq0trDpgxcRkW8KpyN4ERE5iQJeRCRMhVzAm9lwM9toZllmdn8lyxuY2fzA8lQz61wLNXU0s8/MbL2ZrTOzeypZ5xIzO2hm6YGvB72uK9DuNjNbE2gzrZLlZmZ/DWyv1WY2sBZq6nnSdkg3s0NmNuWUdWpte5nZdDPLM7O1Jz0XY2YLzSwz8L1lFa/9aWCdTDP7aS3U9Wcz2xB4r94wsxZVvPa077sHdT1kZjtPer9GVPHa035+Pahr/kk1bTOz9Cpe6+X2qjQfamUfc86FzBcV0w5vBhKBKGAV0PuUdX4O/CPweDQwvxbqagsMDDxuCmyqpK5LgAU+bLNtQNxplo8A3gcMSAFSfXhP91BxsYYv2wsYBgwE1p703J+A+wOP7wf+WMnrYoAtge8tA49belzXVUBk4PEfK6urOu+7B3U9BNxbjff6tJ/fmq7rlOV/AR70YXtVmg+1sY+F2hH8v27k7ZwrAU7cyPtko4AZgcevApebx3fcds7tds6tCDwuBDKouCdtKBgFzHQVlgAtzKxtLbZ/ObDZOXe2VzCfM+fcl8C+U54+eT+aAVxbyUt/ACx0zu1zzu0HFgLDvazLOfeRc6408OMSKu6UVquq2F7VUZ3Pryd1BTLgJmBuTbVXXafJB8/3sVAL+Mpu5H1qkP5rncAH4SAQWyvVAYEuoQFAaiWLh5jZKjN738z61FJJDvjIzJZbxQ3OT1Wdbeql0VT9ofNje53Q2jm3O/B4D9C6knX83na3UfHXV2W+6333wl2BrqPpVXQ3+Lm9vgfkOucyq1heK9vrlHzwfB8LtYAPambWBHgNmOKcO3TK4hVUdEP0B54C3qylsoY65wYCVwN3mtmwWmr3O1nFrRyvAV6pZLFf2+tbXMXfykE1ntjMHgBKgdlVrFLb7/szQFfgAmA3Fd0hwWQMpz9693x7nS4fvNrHQi3gq3Mj73+tY2aRQHNgr9eFmVl9Kt682c65109d7pw75Jw7HHj8HlDfzOK8rss5tzPwPQ94g4o/k0/m583RrwZWOOdyT13g1/Y6Se6JrqrA97xK1vFl25nZeGAk8JNAMHxLNd73GuWcy3XOlTnnyoHnqmjPr+0VCVwPzK9qHa+3VxX54Pk+FmoBX50beb8NnDjTfAPwaVUfgpoS6N+bBmQ45x6vYp02J84FmNlgKra9p//xmFm0mTU98ZiKE3RrT1ntbWCcVUgBDp70Z6PXqjyq8mN7neLk/einwFuVrPMhcJWZtQx0SVwVeM4zZjYcuA+4xjlXVMU61Xnfa7quk8/bXFdFe9X5/HrhCmCDc25HZQu93l6nyQfv9zEvzhp7+UXFqI9NVJyNfyDw3O+p2OEBGlLxJ38WsBRIrIWahlLx59VqID3wNQK4A7gjsM5dwDoqRg4sAS6qhboSA+2tCrR9YnudXJcBfwtszzVAUi29j9FUBHbzk57zZXtR8Z/MbuA4FX2cE6g4b/MJkAl8DMQE1k0Cnj/ptbcF9rUs4NZaqCuLij7ZE/vZiRFj7YD3Tve+e1zXS4H9ZzUVwdX21LoCP3/r8+tlXYHnXzyxX520bm1ur6rywfN9TFMViIiEqVDrohERkWpSwIuIhCkFvIhImFLAi4iEKQW8iEiYUsCLiIQpBbyISJhSwItUwcwGBSbPahi42nGdmfX1uy6R6tKFTiKnYWaPUHF1dCNgh3PuUZ9LEqk2BbzIaQTmTFkGHKNiuoQyn0sSqTZ10YicXizQhIo78TT0uRaRM6IjeJHTMLO3qbjzUBcqJtC6y+eSRKot0u8CRIKVmY0Djjvn5phZBPC1mV3mnPvU79pEqkNH8CIiYUp98CIiYUoBLyISphTwIiJhSgEvIhKmFPAiImFKAS8iEqYU8CIiYer/A46MvXC2X3m7AAAAAElFTkSuQmCC"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "numerical_diff(function_1, 5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1999999999990898"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "numerical_diff(function_1, 10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.2999999999986347"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# 4.3.3 편미분 \r\n",
    "def function_2(x):\r\n",
    "    return x[0]**2 + x[1]**2\r\n",
    "    # 또는 return np.sum(x**2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def function_tmp1(x0):\r\n",
    "    return x0*x0 + 4.0**2.0\r\n",
    "\r\n",
    "numerical_diff(function_tmp1, 3.0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6.00000000000378"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def function_tmp2(x1):\r\n",
    "    return 3.0**2.0 + x1*x1\r\n",
    "\r\n",
    "numerical_diff(function_tmp2, 4.0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# 4.4 기울기 \r\n",
    "# 앞에서는 편미분 할 때 변수 하나씩 따로 하였다 \r\n",
    "# 한꺼번에 해보겠음 \r\n",
    "\r\n",
    "def numerical_gradient(f, x):\r\n",
    "    h = 1e-4 # 0.0001\r\n",
    "    grad = np.zeros_like(x)\r\n",
    "\r\n",
    "    for idx in range(x.size):\r\n",
    "        tmp_val = x[idx]\r\n",
    "\r\n",
    "        x[idx] = tmp_val + h \r\n",
    "        fxh1 = f(x)\r\n",
    "\r\n",
    "        x[idx] = tmp_val - h \r\n",
    "        fxh2 = f(x)\r\n",
    "\r\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h) \r\n",
    "        x[idx] = tmp_val \r\n",
    "\r\n",
    "    return grad"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 4.0]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "numerical_gradient(function_2, np.array([0.0, 2.0]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 0.0]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([6., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# 4.4.1 경사 하강법\r\n",
    "# f : 최적화 하려는 함수\r\n",
    "# init_x : 초깃값 \r\n",
    "# lr = 학습률 \r\n",
    "# step_num : 경사하강법 반복 횟수 \r\n",
    "def gradient_descent(f, init_x, lr = 0.01, step_num = 100):\r\n",
    "    x = init_x \r\n",
    "\r\n",
    "    for i in range(step_num):\r\n",
    "        grad = numerical_gradient(f, x)\r\n",
    "        x -= lr * grad\r\n",
    "    \r\n",
    "    return x "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def fuction_2(x):\r\n",
    "    return x[0]**2 + x[1]**2\r\n",
    "\r\n",
    "init_x = np.array([-3.0, 4.0])\r\n",
    "gradient_descent(function_2, init_x, lr = 0.1, step_num = 100)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# 학습률이 너무 큰 경우\r\n",
    "init_x = np.array([-3.0 , 4.0])\r\n",
    "gradient_descent(function_2, init_x, lr = 10.0, step_num = 100)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-2.58983747e+13, -1.29524862e+12])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# 학습률이 너무 작은 경우\r\n",
    "init_x = np.array([-3.0 , 4.0])\r\n",
    "gradient_descent(function_2, init_x, lr = 1e-10, step_num = 100)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-2.99999994,  3.99999992])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# 간단한 신경망을 통해 실제로 기울기를 구하는 코드\r\n",
    "import sys, os \r\n",
    "sys.path.append(os.pardir)\r\n",
    "import numpy as np\r\n",
    "from common.functions import softmax, cross_entropy_error \r\n",
    "from common.gradient import numerical_gradient\r\n",
    "\r\n",
    "class simpleNet:\r\n",
    "    def __init__(self):\r\n",
    "        self.W = np.random.randn(2, 3) # 형상이 2x3인 가중치 매개변수 하나를 변수로 갖는다. \r\n",
    "\r\n",
    "    def predict(self, x):\r\n",
    "        return np.dot(x, self.W) \r\n",
    "\r\n",
    "    def loss(self, x, t):\r\n",
    "        z = self.predict(x)\r\n",
    "        y = softmax(z)\r\n",
    "        loss = cross_entropy_error(y, t)\r\n",
    "\r\n",
    "        return loss "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "net = simpleNet()\r\n",
    "print(net.W)\r\n",
    "\r\n",
    "x = np.array([0.6, 0.9])\r\n",
    "p = net.predict(x)\r\n",
    "print(p)\r\n",
    "\r\n",
    "np.argmax(p) # 최댓값의 인덱스\r\n",
    "\r\n",
    "t = np.array([0,0,1])\r\n",
    "net.loss(x,t)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.8019647   0.04569553 -0.01149229]\n",
      " [ 1.22215702 -0.13943412 -0.56354579]]\n",
      "[ 1.58112014 -0.09807339 -0.51408659]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.3649038502462276"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# 앞서 만들었던 simpleNet의 기울기를 구함 \r\n",
    "def f(W): # W는 더미 \r\n",
    "    return net.loss(x, t)\r\n",
    "\r\n",
    "dW = numerical_gradient(f, net.W)   # f는 함수, net.W는 함수 f의 인수 \r\n",
    "print(dW)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.45816547  0.08545901 -0.54362448]\n",
      " [ 0.6872482   0.12818852 -0.81543672]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "f892bdf6aaf6a0079611b93749c8a0aa100a791d5095930370274196da5611a3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}