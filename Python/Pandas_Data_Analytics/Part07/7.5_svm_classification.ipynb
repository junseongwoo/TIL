{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM \n",
    "- Support Vector Machine\n",
    "- 데이터프레임의 각 열은 열 벡터 형태로 구현 \n",
    "- 열 벡터들이 각각 고유의 축을 갖는 벡터 공간을 만든다.\n",
    "- 분석 대상이 되는 개별 관측값은 열 벡터에 관한 값을 해당 축의 좌표로 표시하여 벡터 공간에서의 위치를 나타냄\n",
    "- 열 벡터가 2개 존재하는 데이터셋은 2차원 평면 공간에 좌표로 표시\n",
    "- 열 벅테가 3개면 3차원 공간에 표시 \n",
    "- SVM은 벡터 공간에 위치한 훈련 데이터의 좌표와 각 데이터가 어떤 분류 값을 가져야 하는지 정답을 입력 받아 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 개수 :  (499, 9)\n",
      "test 개수 :  (215, 9)\n"
     ]
    }
   ],
   "source": [
    "# Step-1 : 데이터 준비 / 기본 설정 \n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "# Step-2 : 데이터 탐색 / 전처리\n",
    "rdf = df.drop(['deck', 'embark_town'], axis = 1)\n",
    "rdf = rdf.dropna(subset=['age'], how = 'any', axis = 0)\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts(dropna = True).idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "\n",
    "# Step-3 : 분석에 사용할 속성 선택\n",
    "ndf = rdf[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked']]\n",
    "\n",
    "onehot_sex = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf, onehot_sex], axis = 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix = 'town')\n",
    "\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis = 1)\n",
    "ndf.drop(['sex', 'embarked'], axis = 1, inplace = True)\n",
    "\n",
    "# Step-4 : 데이터셋 구분 - 훈련용 / 검증용 \n",
    "\n",
    "X = ndf[['pclass', 'age', 'sibsp', 'parch', 'female', 'male', 'town_C', 'town_Q', 'town_S']]\n",
    "y = ndf['survived']\n",
    "\n",
    "from sklearn import preprocessing \n",
    "X = preprocessing.StandardScaler().fit(X).transform(X) \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "print('train 개수 : ', X_train.shape)\n",
    "print('test 개수 : ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모형 학습 및 검증 \n",
    "- sklearn에서 가져온 svm 모듈의 SVC() 함수를 사용하여 객체 생성 \n",
    "- 데이터를 벡터 공간으로 매핑하는 함수를 kernel이라 함 \n",
    "- kernel = 'rbf' 옵션으로 RBF(Radial Basis Function) 함수를 적용 \n",
    "- train data를 fit() 메소드에 전달하여 모형 학습\n",
    "- test data를 predict() 메소드에 입력하여 예측한 결과를 저장하고 실제 데이터(y_test)와 비교 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 0 0]\n",
      "[0 0 1 0 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Step-5 : SVM 분류 모형(sklearn) 사용\n",
    "\n",
    "from sklearn import svm \n",
    "\n",
    "svm_model = svm.SVC(kernel='rbf')\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_hat = svm_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모형을 예측 능력을 평가하는 지표 계산\n",
    "- confusion_matrix() 함수로 Confusion Matrix 계산\n",
    "- 215명의 승객 중\n",
    "    1. 미생존자를 정확히 예측한 TP : 120명\n",
    "    2. 미생존자를 생존자로 잘못 분류한 FP : 5명\n",
    "    3. 생존자를 미생존자로 잘못 분류한 FN : 35명\n",
    "    4. 생존자를 정확하게 예측한 TN : 55명 \n",
    "- classification_report() 함수로 precision, recall, f1 - score 지표를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120   5]\n",
      " [ 35  55]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86       125\n",
      "           1       0.92      0.61      0.73        90\n",
      "\n",
      "    accuracy                           0.81       215\n",
      "   macro avg       0.85      0.79      0.80       215\n",
      "weighted avg       0.83      0.81      0.81       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "svm_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(svm_matrix)\n",
    "print('\\n')\n",
    "\n",
    "svm_report = metrics.classification_report(y_test, y_hat)\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efddc2e8d2dadd0ba13ae7128c02d630b24f1fdb7d9bd6bad5a6da54781ea1ce"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
